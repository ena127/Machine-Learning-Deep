{"cells":[{"cell_type":"markdown","metadata":{"id":"_jQ1tEQCxwRx"},"source":["##### Copyright 2019 The TensorFlow Authors."]},{"cell_type":"markdown","metadata":{"id":"e1_Y75QXJS6h"},"source":["### 설정"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10146,"status":"ok","timestamp":1719991166092,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"WZKbyU2-AiY-"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1719991166093,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"wx-zNbLqB4K8","outputId":"6dcff92c-99de-44a2-9007-a9cf213bccce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.15.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["tf.__version__"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1719991166093,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"YfIk2es3hJEd"},"outputs":[],"source":["import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from PIL import Image\n","from keras import layers\n","import keras\n","import time\n","\n","from IPython import display"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17946,"status":"ok","timestamp":1719991184033,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"Dd8CI0bVYSNK","outputId":"6f33a4e7-4286-4fd6-daad-74637c556de1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSOP8Tg9VVxT"},"outputs":[],"source":["SIZE = 128"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fr9eED2HfLBs"},"outputs":[],"source":["# 이미지 폴더 경로 설정\n","image_folder = \"/content/drive/MyDrive/MLD_final/WBC_DATA/lymphocyte/\"\n","batch_size = 64\n","LR= 0.0002\n","LOSS='binary_crossentropy'\n","SAVE_DIR = \"/content/drive/MyDrive/MLD_final/results\"\n","EPOCH=300\n","NOISE_INPUT = 50\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iYn4MdZnKCey"},"source":["### 데이터세트 로드 및 준비하기\n","\n","생성자와 감별자 훈련을 위해 MNIST 데이터세트가 사용됩니다. 생성자는 손글씨 숫자 데이터를 닮은 숫자를 생성할 것입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1324,"status":"error","timestamp":1716945875989,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"FoURjvvQelQ7","colab":{"base_uri":"https://localhost:8080/","height":507},"outputId":"9261cacb-23ef-4bb5-bd1c-5f9eceb0ddbe"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"in user code:\n\n    File \"<ipython-input-7-eca3317d7f48>\", line 15, in load_and_preprocess_image  *\n        image = preprocess_image(image)\n    File \"<ipython-input-7-eca3317d7f48>\", line 3, in preprocess_image  *\n        image = tf.image.resize(image, [SIZE, SIZE])\n\n    NameError: name 'SIZE' is not defined\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-eca3317d7f48>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# TensorFlow Dataset 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# 데이터셋 분할 (훈련: 80%, 검증: 20%)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2278\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2280\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     38\u001b[0m         input_dataset, map_func, preserve_cardinality=True, name=name)\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     return _ParallelMapDataset(\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;31m# Implements PolymorphicFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# Note: wrapper_helper will apply autograph based on context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_filedb5k4tui.py\u001b[0m in \u001b[0;36mtf__load_and_preprocess_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_png\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0m_attach_error_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_file5fxcmbdw.py\u001b[0m in \u001b[0;36mtf__preprocess_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: in user code:\n\n    File \"<ipython-input-7-eca3317d7f48>\", line 15, in load_and_preprocess_image  *\n        image = preprocess_image(image)\n    File \"<ipython-input-7-eca3317d7f48>\", line 3, in preprocess_image  *\n        image = tf.image.resize(image, [SIZE, SIZE])\n\n    NameError: name 'SIZE' is not defined\n"]}],"source":["\n","\n","# 이미지 전처리 함수\n","def preprocess_image(image):\n","    image = tf.image.resize(image, [SIZE, SIZE])\n","    image = (image - 127.5) / 127.5  # 픽셀 값을 [-1, 1] 범위로 조정\n","    return image\n","\n","# 파일 경로 리스트 생성\n","image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(('png', 'jpg', 'jpeg'))]\n","\n","# 데이터셋 생성 함수\n","def load_and_preprocess_image(path):\n","    image = tf.io.read_file(path)\n","    # 이미지 파일 형식을 명시적으로 지정 (jpeg 또는 png)\n","    image = tf.image.decode_png(image, channels=3)  # 또는 tf.image.decode_png\n","    image = preprocess_image(image)\n","    return image\n","\n","# TensorFlow Dataset 생성\n","dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n","dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","# 데이터셋 분할 (훈련: 80%, 검증: 20%)\n","dataset_size = len(image_paths)\n","train_size = dataset_size\n","\n","train_dataset = dataset.take(train_size)\n","\n","# DataLoader 설정\n","\n","train_dataset = train_dataset.shuffle(buffer_size=train_size).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","\n","# DataLoader 테스트 (옵션)\n","#for images in train_dataset.take(1):\n","#    print(images.shape)  # 예상 출력: (64, 64, 64, 3)\n","\n","#print(\"train size:\", train_size)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"THY-sZMiQ4UV"},"source":["## 모델 만들기\n"]},{"cell_type":"markdown","metadata":{"id":"-tEyxE-GMC48"},"source":["### 생성자\n","\n","생성자는 시드값(임의의 노이즈)에서 이미지를 생성하기 위해, `tf.keras.layers.Conv2DTranspose`(업샘플링) 레이어를 이용합니다. 처음 `Dense` 레이어는 해당 시드값을 입력값으로 받습니다. 다음으로 원하는 크기인 28x28x1의 이미지에 도달할 때까지 업샘플링을 여러 번 수행합니다. tanh 함수를 사용하는 출력 레이어를 제외한 각 레이어에서 `tf.keras.layers.LeakyReLU` 활성화가 사용됩니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZgMqX1f--vF"},"outputs":[],"source":["\n","generator = tf.keras.Sequential([\n","    # First dense layer\n","    tf.keras.layers.Dense(8 * 8 * 256, use_bias=False, input_shape=[NOISE_INPUT]),\n","    tf.keras.layers.LeakyReLU(),\n","    tf.keras.layers.Reshape((8, 8, 256)),\n","\n","    # First Conv2DTranspose layer\n","    tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","    tf.keras.layers.LeakyReLU(),\n","    tf.keras.layers.Dropout(0.3),\n","\n","    # Second Conv2DTranspose layer\n","    tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","    tf.keras.layers.LeakyReLU(),\n","    tf.keras.layers.Dropout(0.3),\n","\n","    # Third Conv2DTranspose layer\n","    tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","    tf.keras.layers.LeakyReLU(),\n","    tf.keras.layers.Dropout(0.3),\n","\n","    # Fourth Conv2DTranspose layer\n","    tf.keras.layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n","    tf.keras.layers.LeakyReLU(),\n","    tf.keras.layers.Dropout(0.3),\n","\n","    # Output layer\n","    tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh')\n","])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1716945879083,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"lGf_UOWCViUw","outputId":"a031173b-16dc-44c7-c9ef-e39176bf5d9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 16384)             819200    \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 16384)             0         \n","                                                                 \n"," reshape (Reshape)           (None, 8, 8, 256)         0         \n","                                                                 \n"," conv2d_transpose (Conv2DTr  (None, 16, 16, 128)       819200    \n"," anspose)                                                        \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n","                                                                 \n"," dropout (Dropout)           (None, 16, 16, 128)       0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2D  (None, 32, 32, 64)        204800    \n"," Transpose)                                                      \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 64)        0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 32, 32, 64)        0         \n","                                                                 \n"," conv2d_transpose_2 (Conv2D  (None, 64, 64, 32)        51200     \n"," Transpose)                                                      \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 32)        0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 64, 64, 32)        0         \n","                                                                 \n"," conv2d_transpose_3 (Conv2D  (None, 128, 128, 16)      12800     \n"," Transpose)                                                      \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 128, 128, 16)      0         \n","                                                                 \n"," dropout_3 (Dropout)         (None, 128, 128, 16)      0         \n","                                                                 \n"," conv2d_transpose_4 (Conv2D  (None, 128, 128, 3)       1200      \n"," Transpose)                                                      \n","                                                                 \n","=================================================================\n","Total params: 1908400 (7.28 MB)\n","Trainable params: 1908400 (7.28 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["\n","\n","generator.summary()\n"]},{"cell_type":"markdown","metadata":{"id":"klgJw8NJVn4p"},"source":["# testing the generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MoV_2ocDYO8z"},"outputs":[],"source":["def plot_results(images, n_cols=None):\n","    '''visualizes fake images'''\n","    display.clear_output(wait=False)\n","\n","    n_cols = n_cols or len(images)\n","    n_rows = (len(images) - 1) // n_cols + 1\n","\n","    if images.shape[-1] == 1:\n","        images = np.squeeze(images, axis=-1)\n","\n","    plt.figure(figsize=(16, 16))\n","\n","    for index, image in enumerate(images):\n","        plt.subplot(n_rows, n_cols, index + 1)\n","\n","        # NaN 값을 0으로 대체\n","        image = np.nan_to_num(image)\n","\n","        # 이미지를 정규화하여 [0, 1] 범위로 조정\n","        image = (image - np.min(image)) / (np.max(image) - np.min(image))\n","\n","        plt.imshow(image, cmap='gray' if images.shape[-1] == 1 else None)\n","        plt.axis(\"off\")\n","\n","    plt.show()\n","\n","\n","# generate a batch of noise input (batch size = 16)\n","#we got 16 noises to generate 16 images.\n","#test_noise = tf.random.normal([4, noise_input])\n","\n","# feed the batch to the untrained generator\n","#test_image = generator(test_noise)\n","\n","#print(f'Shape of the sample image: {sample_image_normalized}')\n","\n","# visualize sample output\n","#plot_results(test_image, n_cols=4)\n","\n","#print(f'shape of the generated batch: {test_image.shape}')"]},{"cell_type":"markdown","metadata":{"id":"GyWgG09LCSJl"},"source":["(아직 훈련되지 않은) 생성자를 이용해 이미지를 생성해 보겠습니다."]},{"cell_type":"markdown","metadata":{"id":"D0IKnaCtg6WE"},"source":["### 감별자\n","\n","감별자는 컨볼루셔널 신경망(Convolutional Neural Network, CNN) 기반의 이미지 분류자입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3TRKmBBXBdqM"},"outputs":[],"source":["discriminator = keras.models.Sequential([\n","    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"SAME\",\n","                        activation=keras.layers.LeakyReLU(0.2),\n","                        input_shape=[128, 128, 3]),\n","    keras.layers.Dropout(0.4),\n","    keras.layers.Conv2D(64, kernel_size=3, strides=2, padding=\"SAME\",\n","                        activation=keras.layers.LeakyReLU(0.2)),\n","    keras.layers.Dropout(0.4),\n","    keras.layers.Conv2D(64, kernel_size=3, strides=2, padding=\"SAME\",\n","                        activation=keras.layers.LeakyReLU(0.2)),\n","    keras.layers.Dropout(0.4),\n","    keras.layers.Conv2D(64, kernel_size=3, strides=2, padding=\"SAME\",\n","                        activation=keras.layers.LeakyReLU(0.2)),\n","    keras.layers.Dropout(0.4),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(1, activation=\"sigmoid\")\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716945884825,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"JnyoRxouWE3T","outputId":"4392d471-2306-4786-b220-b2fba58761f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 64, 64, 64)        4864      \n","                                                                 \n"," dropout_4 (Dropout)         (None, 64, 64, 64)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n","                                                                 \n"," dropout_5 (Dropout)         (None, 32, 32, 64)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 16, 16, 64)        36928     \n","                                                                 \n"," dropout_6 (Dropout)         (None, 16, 16, 64)        0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n","                                                                 \n"," dropout_7 (Dropout)         (None, 8, 8, 64)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 4096)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 4097      \n","                                                                 \n","=================================================================\n","Total params: 119745 (467.75 KB)\n","Trainable params: 119745 (467.75 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["discriminator.summary()\n"]},{"cell_type":"markdown","metadata":{"id":"QhPneagzCaQv"},"source":["(아직까지 훈련되지 않은) 감별자를 사용하여 생성된 이미지가 진짜인지 가짜인지 판별합니다. 진짜 이미지에는 양수의 값을, 가짜 이미지에는 음수의 값을 출력하도록 모델이 훈련됩니다."]},{"cell_type":"markdown","metadata":{"id":"0FMYgY_mPfTi"},"source":["## 손실과 옵티마이저 정의하기\n","\n","두 모델의 손실 함수와 옵티마이저를 정의합니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6pPx_d3WJO7"},"outputs":[],"source":["#The Adam optimizer is configured according to the recommended configuration in GAN Hacks.\n","optimizer = keras.optimizers.Adam(learning_rate=LR, beta_1=0.5)\n","legacy_opt = keras.optimizers.legacy.Adam(learning_rate=LR, beta_1=0.5)\n","\n","discriminator.compile(loss=LOSS, optimizer=legacy_opt, metrics=['accuracy'])\n","generator.compile(loss=LOSS, optimizer=legacy_opt)\n","\n","#mark the layes of the discriminator as non trainables.\n","discriminator.trainable = False\n"]},{"cell_type":"markdown","metadata":{"id":"8t0_WOc4WRqW"},"source":["# GAN 생성 & 훈련"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1716945889112,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"GetSEXCQWQHj","outputId":"92653bac-fcf8-42d8-81b7-f91bdfd991dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential (Sequential)     (None, 128, 128, 3)       1908400   \n","                                                                 \n"," sequential_1 (Sequential)   (None, 1)                 119745    \n","                                                                 \n","=================================================================\n","Total params: 2028145 (7.74 MB)\n","Trainable params: 1908400 (7.28 MB)\n","Non-trainable params: 119745 (467.75 KB)\n","_________________________________________________________________\n"]}],"source":["#The gan is formed by the generator and the discriminator\n","gan = keras.models.Sequential([generator, discriminator])\n","\n","#we use the same optimize as for the discriminator\n","gan.compile(loss=LOSS, optimizer=optimizer)\n","\n","gan.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":452,"status":"error","timestamp":1716945893515,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"6vfQUqJOWWRM","colab":{"base_uri":"https://localhost:8080/","height":216},"outputId":"40415aad-d5bb-4dd9-bf86-57f8acad80fe"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'SIZE' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-20bf927acdf2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mplot_and_save_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_cols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'SIZE' is not defined"]}],"source":["\n","\n","\n","\n","def plot_and_save_results(images, n_cols=None, save_path=None, figsize=(SIZE, SIZE)):\n","\n","    display.clear_output(wait=False)\n","\n","    n_cols = n_cols or len(images)\n","    n_rows = (len(images) - 1) // n_cols + 1\n","\n","    if images.shape[-1] == 1:\n","        images = np.squeeze(images, axis=-1)\n","\n","    plt.figure(figsize=figsize)  # Adjust the figsize parameter to make the images larger\n","\n","    for index, image in enumerate(images):\n","        plt.subplot(n_rows, n_cols, index + 1)\n","\n","        # Replace NaN values with 0\n","        image = np.nan_to_num(image)\n","\n","        # Normalize the image\n","        image = (image - np.min(image)) / (np.max(image) - np.min(image))\n","# 이미지 안 보이게 할거면 이 부분 수정\n","        plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n","        plt.axis(\"off\")\n","    plt.show()\n","\n","    if save_path:\n","        plt.savefig(save_path)\n","\n","\n","\n","def train_gan(gan, dataset, random_normal_dimensions, save_dir, n_epochs=30):\n","\n","    # GAN에서 생성기와 판별기를 얻습니다.\n","    generator, discriminator = gan.layers\n","\n","    for epoch in range(n_epochs):\n","        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n","        #idx=0\n","\n","        # 데이터를 배치로 로드합니다.\n","        for real_images in dataset:\n","            # 배치 중 얼마나 진행됐는지확인용\n","            #print(\"idx: \", idx, \"/\", len(dataset))\n","            #idx+=1\n","\n","            # 배치 크기 추론\n","            batch_size = real_images.shape[0]\n","\n","            # 판별기 훈련\n","            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n","            fake_images = generator(noise)\n","            mixed_images = tf.concat([fake_images, real_images], axis=0)\n","            discriminator_labels = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n","\n","            discriminator.trainable = True\n","            discriminator.train_on_batch(mixed_images, discriminator_labels)\n","\n","            # 생성기 훈련\n","            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n","            generator_labels = tf.constant([[1.]] * batch_size)\n","\n","            discriminator.trainable = False\n","            gan.train_on_batch(noise, generator_labels)\n","\n","        plot_and_save_results(fake_images, n_cols=8)\n","\n","        if epoch%10==0:\n","              save_path = f\"{save_dir}/epoch_{epoch + 1}.png\"\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"error","timestamp":1716945895097,"user":{"displayName":"127 ENA","userId":"00901681442892532189"},"user_tz":-540},"id":"DvggCrUvSEzg","colab":{"base_uri":"https://localhost:8080/","height":216},"outputId":"2a633d69-439f-4858-b606-c3d136bf9f42"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'SIZE' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-abb673381765>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mplot_and_save_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_cols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'SIZE' is not defined"]}],"source":["def plot_and_save_results(images, n_cols=None, save_path=None, figsize=(SIZE, SIZE)):\n","\n","    display.clear_output(wait=False)\n","\n","    n_cols = n_cols or len(images)\n","    n_rows = (len(images) - 1) // n_cols + 1\n","\n","    if images.shape[-1] == 1:\n","        images = np.squeeze(images, axis=-1)\n","\n","    plt.figure(figsize=figsize)  # Adjust the figsize parameter to make the images larger\n","\n","    for index, image in enumerate(images):\n","        plt.subplot(n_rows, n_cols, index + 1)\n","\n","        # Replace NaN values with 0\n","        image = np.nan_to_num(image)\n","\n","        # Normalize the image\n","        image = (image - np.min(image)) / (np.max(image) - np.min(image))\n","# 이미지 안 보이게 할거면 이 부분 수정\n","        plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n","        plt.axis(\"off\")\n","    plt.show()\n","\n","    if save_path:\n","        plt.savefig(save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xtYIDmMHSD6a"},"outputs":[],"source":["def train_gan(gan, dataset, random_normal_dimensions, save_dir, n_epochs=30):\n","    # GAN에서 생성기와 판별기를 얻습니다.\n","    generator, discriminator = gan.layers\n","\n","    for epoch in range(n_epochs):\n","        print(f\"Epoch {epoch + 1}/{n_epochs}\")\n","        epoch_discriminator_loss = []\n","        epoch_generator_loss = []\n","\n","        # 데이터를 배치로 로드합니다.\n","        for real_images in dataset:\n","            # 배치 크기 추론\n","            batch_size = real_images.shape[0]\n","\n","            # 판별기 훈련\n","            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n","            fake_images = generator(noise)\n","            mixed_images = tf.concat([fake_images, real_images], axis=0)\n","            discriminator_labels = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n","\n","            discriminator.trainable = True\n","            d_loss = discriminator.train_on_batch(mixed_images, discriminator_labels)\n","            epoch_discriminator_loss.append(d_loss)\n","\n","            # 생성기 훈련\n","            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n","            generator_labels = tf.constant([[1.]] * batch_size)\n","\n","            discriminator.trainable = False\n","            g_loss = gan.train_on_batch(noise, generator_labels)\n","            epoch_generator_loss.append(g_loss)\n","\n","        avg_d_loss = np.mean(epoch_discriminator_loss, axis=0)\n","        avg_g_loss = np.mean(epoch_generator_loss, axis=0)\n","        print(f\"Discriminator loss: {avg_d_loss[0]:.4f}, accuracy: {avg_d_loss[1]:.4f}\")\n","        print(f\"Generator loss: {avg_g_loss:.4f}\")\n","\n","        # Generate and save images after each epoch\n","        noise = tf.random.normal([batch_size, random_normal_dimensions])\n","        generated_images = generator(noise)\n","        plot_and_save_results(generated_images, n_cols=8)\n","\n","        if epoch % 10 == 0:\n","            save_path = f\"{save_dir}/epoch_{epoch + 1}.png\"\n","            plot_and_save_results(generated_images, n_cols=8, save_path=save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1_oJm5gdVH_VgIksVqk1nTcgz42LFu3TI"},"id":"GUWGJRDsWY4B","outputId":"0ac5d62e-52bf-4b1f-a8b5-32d6526aa23b"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from datetime import datetime\n","\n","# 현재 날짜와 시간 가져오기\n","now = datetime.now()\n","\n","# 날짜와 시간 포맷팅\n","formatted_now = now.strftime(\"%m%d_%H:%M\")\n","\n","save_path = SAVE_DIR+formatted_now+\"/\"\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","train_gan(gan, train_dataset, NOISE_INPUT,save_dir=SAVE_DIR, n_epochs=EPOCH)\n","# 최종 생성자 모델 저장\n","generator.save_weights('generator_ne_{}.h5'.format(EPOCH))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"ccGEFMDQCgnR","executionInfo":{"status":"error","timestamp":1716945903344,"user_tz":-540,"elapsed":937,"user":{"displayName":"127 ENA","userId":"00901681442892532189"}},"outputId":"0851b2b0-24f2-45a9-d24c-714c1fcbae58"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Cannot assign value to variable ' conv2d_transpose/kernel:0': Shape mismatch.The variable shape (5, 5, 128, 256), and the assigned value shape (256, 128, 3, 3) are incompatible.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-04bbad16d021>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLOADMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/MLD_final/generator_ep_1200_k3.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOADMODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 랜덤 노이즈 벡터 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_examples_to_generate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36m_assign_value_to_variable\u001b[0;34m(variable, value)\u001b[0m\n\u001b[1;32m   4357\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4358\u001b[0m         \u001b[0;31m# For the normal tf.Variable assign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4359\u001b[0;31m         \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot assign value to variable ' conv2d_transpose/kernel:0': Shape mismatch.The variable shape (5, 5, 128, 256), and the assigned value shape (256, 128, 3, 3) are incompatible."]}],"source":["LOADMODEL = \"/content/drive/MyDrive/MLD_final/generator_ep_1200_k3.h5\"\n","generator.load_weights(LOADMODEL)\n","\n","# 랜덤 노이즈 벡터 생성\n","num_examples_to_generate = 16\n","random_vector_for_generation = tf.random.normal([num_examples_to_generate, 100])\n","\n","# 이미지 생성 및 저장\n","def generate_and_save_images(model, epoch, test_input):\n","    predictions = model(test_input, training=False)\n","\n","    fig = plt.figure(figsize=(4, 4))\n","\n","    for i in range(predictions.shape[0]):\n","        plt.subplot(4, 4, i+1)\n","        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n","        plt.axis('off')\n","\n","    plt.savefig(f'image_at_epoch_{epoch:04d}.png')\n","    plt.show()\n","\n","generate_and_save_images(generator, 0, random_vector_for_generation)"]},{"cell_type":"markdown","metadata":{"id":"PKY_iPSPNWoj"},"source":["### 감별자 손실\n","\n","이 메서드는 감별자가 가짜 이미지와 진짜 이미지를 얼마나 잘 판별하는지 수치화합니다. 진짜 이미지에 대한 감별자의 예측과 1로 이루어진 배열을 비교하고, 가짜로 (생성된) 이미지에 대한 감별자의 예측과 0으로 이루어진 배열을 비교합니다."]},{"cell_type":"markdown","metadata":{"id":"Jd-3GCUEiKtv"},"source":["### 생성자 손실\n","\n","생성자의 손실은 판별자를 얼마나 잘 속일 수 있었는지를 수치화합니다. 직관적으로, 생성자가 잘 작동하면 판별자는 가짜 이미지를 실제(또는 1)로 분류합니다. 여기에서 생성된 이미지에 대한 판별자의 판단을 1의 배열과 비교합니다."]},{"cell_type":"markdown","metadata":{"id":"MgIc7i0th_Iu"},"source":["판별자와 생성자 옵티마이저는 두 네트워크를 별도로 훈련하기 때문에 서로 다릅니다."]},{"cell_type":"markdown","metadata":{"id":"mWtinsGDPJlV"},"source":["### 체크포인트 저장하기\n","\n","이 노트북은 오랫동안 진행되는 훈련이 중단된 경우 유용한 모델의 저장 및 복구 방법을 보여줍니다."]},{"cell_type":"markdown","metadata":{"id":"Rw1fkAczTQYh"},"source":["## 훈련 루프 정의하기\n"]},{"cell_type":"markdown","metadata":{"id":"jylSonrqSWfi"},"source":["생성자가 입력으로 임의의 시드를 받으면 훈련 루프가 시작됩니다. 해당 시드는 이미지를 생성하는 데 사용됩니다. 감별자를 사용하여 (훈련 세트에서 가져온) 진짜 이미지와 (생성자를 통해 생성된) 가짜 이미지를 분류합니다. 각 모델의 손실을 계산하고, 그래디언트를 사용해 생성자와 감별자를 업데이트합니다."]},{"cell_type":"markdown","metadata":{"id":"2aFF7Hk3XdeW"},"source":["**이미지 생성 및 저장하기**\n"]},{"cell_type":"markdown","metadata":{"id":"dZrd4CdjR-Fp"},"source":["## 모델 훈련하기\n","\n","위에서 정의한 `train()` 메서드를 호출하여 생성자와 판별자를 동시에 훈련합니다. GAN 훈련은 까다로울 수 있습니다. 생성자와 판별자가 서로를 압도하지 않는 것이 중요합니다(예: 비슷한 속도로 훈련됨).\n","\n","훈련 초기에 생성된 이미지는 무작위 노이즈처럼 보입니다. 훈련이 진행됨에 따라 생성된 숫자는 점점 더 실제처럼 보일 것입니다. 약 50 epoch 후에는 MNIST 숫자와 유사합니다. Colab의 기본 설정에서 이 작업은 epoch당 약 1분 정도 소요될 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"rfM4YcPVPkNO"},"source":["마지막 체크포인트를 복구합니다."]},{"cell_type":"markdown","metadata":{"id":"P4M_vIbUi7c0"},"source":["## GIF 생성하기\n"]},{"cell_type":"markdown","metadata":{"id":"NywiH3nL8guF"},"source":["`imageio`를 통해 훈련 중 저장된 이미지를 사용한 GIF 애니메이션을 만듭니다."]},{"cell_type":"markdown","metadata":{"id":"k6qC-SbjK0yW"},"source":["## 다음 단계\n"]},{"cell_type":"markdown","metadata":{"id":"xjjkT9KAK6H7"},"source":["이 튜토리얼은 GAN을 작성하고 훈련하는 데 필요한 전체 코드를 보여주었습니다. 다음 단계로 [Kaggle에서 사용할 수 있는](https://www.kaggle.com/jessicali9530/celeba-dataset) 대규모 유명인 얼굴 특성(CelebA) 데이터세트와 같은 다른 데이터세트를 실험해볼 수 있습니다. GAN에 대해 자세히 알아보려면 [NIPS 2016 튜토리얼: 생성적 적대 네트워크](https://arxiv.org/abs/1701.00160)를 참조하세요.\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1-wf7eFQMSqe2b0O_qfoXQjXGJJekML58","timestamp":1716261049365},{"file_id":"1O_ZW5x5xcS790x8dSTbAdMnAasmF8CQg","timestamp":1716202841818}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}